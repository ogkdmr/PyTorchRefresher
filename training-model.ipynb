{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bbdd67",
   "metadata": {},
   "source": [
    "## Recap: Data Pipeline, Network Building, Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10328504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import datasets \n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0e28f",
   "metadata": {},
   "source": [
    "### Download the data, build the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876c1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the datasets.\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root = 'data', \n",
    "    download = True, \n",
    "    transform = ToTensor(),\n",
    "    train = True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    download = True,\n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "#Building the dataloaders. \n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=64, \n",
    "                             shuffle=True,\n",
    "                              drop_last=True, #guarantees that each batch has same size.\n",
    "                             num_workers = 12\n",
    "                             )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                            batch_size=64,\n",
    "                            drop_last =True,\n",
    "                            num_workers = 12\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e094f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b26c7",
   "metadata": {},
   "source": [
    "### Define the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b20eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self, img_h, img_w, hid_dim, num_classes):\n",
    "        super(FashionClassifier, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(img_h * img_w, hid_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hid_dim, hid_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hid_dim, hid_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hid_dim, hid_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hid_dim, num_classes), \n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h = self.flatten(X)\n",
    "        out = self.backbone(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3a9c2",
   "metadata": {},
   "source": [
    "### Remember to push the model to the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9928cd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model = FashionClassifier(28, 28, 512, 10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1c07c",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c96600",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3 \n",
    "batch_size = 64 # defining here, though it should be passed to the DataLoader in initalization.\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c585c5",
   "metadata": {},
   "source": [
    "### Define the Loss Function and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448c1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() #this is like Keras' SparseCategoricalCrossEntropy(with_logits=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9bcb7",
   "metadata": {},
   "source": [
    "### Define the Train Loop and Test Loop for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14d6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    model.train() # put the model to training mode in case it is not.\n",
    "    num_samples = len(train_dataloader.dataset)\n",
    "    epoch_loss, batches, true_preds= 0 , 0 , 0\n",
    "    \n",
    "    #training step.\n",
    "    for (X, y) in train_dataloader:\n",
    "        batches += 1\n",
    "        X, y = X.to(device), y.to(device) #load the tensors to GPU.\n",
    "        optimizer.zero_grad() #refresh the gradients.\n",
    "        preds = model(X) #feedforward\n",
    "        true_preds += (preds.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "        step_loss = loss_fn(preds, y) # remember, gt is second in pytorch. it is first in TF.\n",
    "        epoch_loss += step_loss.item()\n",
    "        step_loss.backward() #backprop\n",
    "        optimizer.step() #apply the gradients.\n",
    "    \n",
    "    print(\"Train loss: {}, Train acc: {}\".format(epoch_loss/batches, true_preds / num_samples))\n",
    "                \n",
    "        \n",
    "def test_loop(test_dataloader, model, loss_fn):\n",
    "        \n",
    "    model.eval() #freeze the model weights, no need to save gradients here.\n",
    "    num_samples = len(test_dataloader.dataset)\n",
    "    epoch_loss, batches, true_preds = 0, 0, 0 \n",
    "\n",
    "    for X,y in test_dataloader:\n",
    "        batches += 1\n",
    "        X, y = X.to(device), y.to(device) # load the tensors to GPU.\n",
    "        preds = model(X)\n",
    "        true_preds += (preds.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "        step_loss = loss_fn(preds, y)\n",
    "        epoch_loss += step_loss.item()\n",
    "        \n",
    "    print('Validation loss: {}, Validation acc: {}'.format(epoch_loss/batches, true_preds/num_samples))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6067ddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch: 1 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.7199296775406173, Train acc: 0.7299166666666667\n",
      "Validation loss: 0.4758479727957493, Validation acc: 0.8253\n",
      "\n",
      " Epoch: 2 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.521345610965914, Train acc: 0.8162333333333334\n",
      "Validation loss: 0.4462082364047185, Validation acc: 0.8388\n",
      "\n",
      " Epoch: 3 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4826131201445611, Train acc: 0.8296833333333333\n",
      "Validation loss: 0.41621488695725417, Validation acc: 0.8477\n",
      "\n",
      " Epoch: 4 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4672902920139256, Train acc: 0.8372166666666667\n",
      "Validation loss: 0.4297080136453494, Validation acc: 0.8483\n",
      "\n",
      " Epoch: 5 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.44698744970935383, Train acc: 0.8424333333333334\n",
      "Validation loss: 0.3878153860569, Validation acc: 0.8583\n",
      "\n",
      " Epoch: 6 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.43748718283855803, Train acc: 0.8466166666666667\n",
      "Validation loss: 0.3881936283447804, Validation acc: 0.8576\n",
      "\n",
      " Epoch: 7 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.43627187633527126, Train acc: 0.8476833333333333\n",
      "Validation loss: 0.3835963161709981, Validation acc: 0.8645\n",
      "\n",
      " Epoch: 8 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4322569145082537, Train acc: 0.8495666666666667\n",
      "Validation loss: 0.38886431174782604, Validation acc: 0.8616\n",
      "\n",
      " Epoch: 9 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.42301304660650046, Train acc: 0.8523166666666666\n",
      "Validation loss: 0.3931746903138283, Validation acc: 0.8643\n",
      "\n",
      " Epoch: 10 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.42024891841818707, Train acc: 0.8529166666666667\n",
      "Validation loss: 0.3855264021609074, Validation acc: 0.8593\n",
      "\n",
      " Epoch: 11 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4161761714783651, Train acc: 0.85545\n",
      "Validation loss: 0.381213696148151, Validation acc: 0.8691\n",
      "\n",
      " Epoch: 12 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4095373017238324, Train acc: 0.8569666666666667\n",
      "Validation loss: 0.37299349760779965, Validation acc: 0.8681\n",
      "\n",
      " Epoch: 13 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.41170215687795025, Train acc: 0.8587833333333333\n",
      "Validation loss: 0.37593578040981906, Validation acc: 0.8694\n",
      "\n",
      " Epoch: 14 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.4096240951513659, Train acc: 0.8567833333333333\n",
      "Validation loss: 0.39127507337774986, Validation acc: 0.8654\n",
      "\n",
      " Epoch: 15 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.40488303255532315, Train acc: 0.8599166666666667\n",
      "Validation loss: 0.3896329761124574, Validation acc: 0.8641\n",
      "\n",
      " Epoch: 16 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.40249522761098855, Train acc: 0.8595\n",
      "Validation loss: 0.3799856275511094, Validation acc: 0.8656\n",
      "\n",
      " Epoch: 17 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.40033716984339685, Train acc: 0.86215\n",
      "Validation loss: 0.3755284364406879, Validation acc: 0.8698\n",
      "\n",
      " Epoch: 18 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.40199900840746045, Train acc: 0.8606333333333334\n",
      "Validation loss: 0.37086666251222294, Validation acc: 0.8699\n",
      "\n",
      " Epoch: 19 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3897158408352634, Train acc: 0.8644\n",
      "Validation loss: 0.37872581976728564, Validation acc: 0.8715\n",
      "\n",
      " Epoch: 20 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3967668763028901, Train acc: 0.8630833333333333\n",
      "Validation loss: 0.3681960061001472, Validation acc: 0.8699\n",
      "\n",
      " Epoch: 21 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3880375317330676, Train acc: 0.8646833333333334\n",
      "Validation loss: 0.38356322155166894, Validation acc: 0.8693\n",
      "\n",
      " Epoch: 22 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3941104154290359, Train acc: 0.8644666666666667\n",
      "Validation loss: 0.3949290390771169, Validation acc: 0.8615\n",
      "\n",
      " Epoch: 23 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3944055101055982, Train acc: 0.8646666666666667\n",
      "Validation loss: 0.3894476693792221, Validation acc: 0.8704\n",
      "\n",
      " Epoch: 24 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3895224351734082, Train acc: 0.8664833333333334\n",
      "Validation loss: 0.3740172356558152, Validation acc: 0.8689\n",
      "\n",
      " Epoch: 25 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3888092065665358, Train acc: 0.8645666666666667\n",
      "Validation loss: 0.377485190733121, Validation acc: 0.8654\n",
      "\n",
      " Epoch: 26 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3926349403525493, Train acc: 0.8641166666666666\n",
      "Validation loss: 0.37888196368630117, Validation acc: 0.8745\n",
      "\n",
      " Epoch: 27 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.38528624654865823, Train acc: 0.8681166666666666\n",
      "Validation loss: 0.39022482282076126, Validation acc: 0.8682\n",
      "\n",
      " Epoch: 28 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.38438427736117975, Train acc: 0.86765\n",
      "Validation loss: 0.3774249210762672, Validation acc: 0.8671\n",
      "\n",
      " Epoch: 29 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.3796333246958803, Train acc: 0.8672666666666666\n",
      "Validation loss: 0.38534200497162646, Validation acc: 0.8623\n",
      "\n",
      " Epoch: 30 \n",
      " -------------- \n",
      " \n",
      "Train loss: 0.39009013242439117, Train acc: 0.8651166666666666\n",
      "Validation loss: 0.39839010848066747, Validation acc: 0.8636\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch: %s \\n -------------- \\n '%(epoch + 1))\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_env] *",
   "language": "python",
   "name": "conda-env-torch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
